{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка и предобработка данных CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 0us/step\n",
      "Размер обучающей выборки: (50000, 32, 32, 3)\n",
      "Размер тестовой выборки: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка данных CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Нормализация данных (приведение значений пикселей к диапазону [0, 1])\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Преобразование меток в one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Вывод информации о данных\n",
    "print(\"Размер обучающей выборки:\", x_train.shape)\n",
    "print(\"Размер тестовой выборки:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификация изображений с помощью SVM и KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность KNN: 25.90%\n",
      "Точность SVM: 44.34%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Используем подвыборку данных для ускорения обучения\n",
    "x_train_subset = x_train[:5000].reshape(5000, -1)  # Преобразуем изображения в одномерные векторы\n",
    "y_train_subset = np.argmax(y_train[:5000], axis=1)\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(x_train_subset, y_train_subset)\n",
    "y_pred_knn = knn.predict(x_test_flat)\n",
    "accuracy_knn = accuracy_score(np.argmax(y_test, axis=1), y_pred_knn)\n",
    "print(f\"Точность KNN: {accuracy_knn * 100:.2f}%\")\n",
    "\n",
    "# SVM\n",
    "svm = SVC()\n",
    "svm.fit(x_train_subset, y_train_subset)\n",
    "y_pred_svm = svm.predict(x_test_flat)\n",
    "accuracy_svm = accuracy_score(np.argmax(y_test, axis=1), y_pred_svm)\n",
    "print(f\"Точность SVM: {accuracy_svm * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание многослойного перцептрона (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 49ms/step - accuracy: 0.2225 - loss: 2.2143 - val_accuracy: 0.3444 - val_loss: 1.8458\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 40ms/step - accuracy: 0.3221 - loss: 1.8649 - val_accuracy: 0.3698 - val_loss: 1.7639\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 42ms/step - accuracy: 0.3489 - loss: 1.7929 - val_accuracy: 0.3838 - val_loss: 1.7284\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 41ms/step - accuracy: 0.3598 - loss: 1.7747 - val_accuracy: 0.3781 - val_loss: 1.7266\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 58ms/step - accuracy: 0.3718 - loss: 1.7304 - val_accuracy: 0.3848 - val_loss: 1.6899\n",
      "Epoch 6/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 49ms/step - accuracy: 0.3824 - loss: 1.7176 - val_accuracy: 0.3992 - val_loss: 1.6707\n",
      "Epoch 7/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 42ms/step - accuracy: 0.3893 - loss: 1.6963 - val_accuracy: 0.4216 - val_loss: 1.6306\n",
      "Epoch 8/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.3996 - loss: 1.6642 - val_accuracy: 0.4265 - val_loss: 1.6454\n",
      "Epoch 9/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 43ms/step - accuracy: 0.4013 - loss: 1.6662 - val_accuracy: 0.4331 - val_loss: 1.6031\n",
      "Epoch 10/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 42ms/step - accuracy: 0.4082 - loss: 1.6456 - val_accuracy: 0.4293 - val_loss: 1.5993\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4443 - loss: 1.5697\n",
      "Точность MLP на тестовых данных:  43.86%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, InputLayer\n",
    "\n",
    "# Создание модели MLP\n",
    "model_mlp = Sequential([\n",
    "    InputLayer(shape=(32, 32, 3)),  # Указываем входную форму\n",
    "    Flatten(),  # Преобразуем изображение в одномерный вектор\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')  # Выходной слой для 10 классов\n",
    "])\n",
    "\n",
    "# Компиляция модели\n",
    "model_mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Обучение модели\n",
    "history_mlp = model_mlp.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Оценка точности на тестовых данных\n",
    "test_loss_mlp, test_accuracy_mlp = model_mlp.evaluate(x_test, y_test)\n",
    "print(f\"Точность MLP на тестовых данных:  {test_accuracy_mlp * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание сверточной нейронной сети (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YasperMoglot\\Desktop\\Ycheba\\4course\\raspoznavanie-obrazov\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 43ms/step - accuracy: 0.3279 - loss: 1.8228 - val_accuracy: 0.5073 - val_loss: 1.3832\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.5255 - loss: 1.3230 - val_accuracy: 0.5931 - val_loss: 1.1542\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 45ms/step - accuracy: 0.5971 - loss: 1.1449 - val_accuracy: 0.6218 - val_loss: 1.0782\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 45ms/step - accuracy: 0.6331 - loss: 1.0495 - val_accuracy: 0.6462 - val_loss: 1.0005\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 43ms/step - accuracy: 0.6607 - loss: 0.9575 - val_accuracy: 0.6611 - val_loss: 0.9697\n",
      "Epoch 6/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.6871 - loss: 0.8948 - val_accuracy: 0.6855 - val_loss: 0.9086\n",
      "Epoch 7/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.7118 - loss: 0.8281 - val_accuracy: 0.6850 - val_loss: 0.8995\n",
      "Epoch 8/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 47ms/step - accuracy: 0.7234 - loss: 0.7842 - val_accuracy: 0.6972 - val_loss: 0.8822\n",
      "Epoch 9/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 47ms/step - accuracy: 0.7450 - loss: 0.7266 - val_accuracy: 0.7031 - val_loss: 0.8697\n",
      "Epoch 10/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 52ms/step - accuracy: 0.7621 - loss: 0.6746 - val_accuracy: 0.7041 - val_loss: 0.8569\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7046 - loss: 0.8646\n",
      "Точность CNN на тестовых данных: 70.08%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# Создание модели CNN\n",
    "model_cnn = Sequential([\n",
    "    InputLayer(shape=(32, 32, 3)),  # Указываем входную форму\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Компиляция модели\n",
    "model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Обучение модели\n",
    "history_cnn = model_cnn.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Оценка точности на тестовых данных\n",
    "test_loss_cnn, test_accuracy_cnn = model_cnn.evaluate(x_test, y_test)\n",
    "print(f\"Точность CNN на тестовых данных: {test_accuracy_cnn * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализация результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Функция для отображения изображений и предсказаний\n",
    "def plot_images(images, labels, predictions, num_images=5):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f\"True: {np.argmax(labels[i])}\\nPred: {predictions[i]}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Предсказания для тестовых данных\n",
    "y_pred_mlp = np.argmax(model_mlp.predict(x_test), axis=1)\n",
    "y_pred_cnn = np.argmax(model_cnn.predict(x_test), axis=1)\n",
    "\n",
    "# Визуализация результатов\n",
    "plot_images(x_test, y_test, y_pred_knn, num_images=5)  # KNN\n",
    "plot_images(x_test, y_test, y_pred_svm, num_images=5)  # SVM\n",
    "plot_images(x_test, y_test, y_pred_mlp, num_images=5)  # MLP\n",
    "plot_images(x_test, y_test, y_pred_cnn, num_images=5)  # CNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fc6d4a912d33d35b6d16af5653b21632918d4e0bd0e360c7180c63eff60aaf8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
